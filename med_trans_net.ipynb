{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20cc11ce-5722-4bf5-86e2-862648cbafbf",
   "metadata": {},
   "source": [
    "# Building and Training MedGraphTrans - A Heterogeneous Graph Transformer based model used to provid context for LLMs in the medical doamin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf9a86-9209-47d0-9572-258a0ef463ed",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9135f772-4d71-46d2-8ae7-16d08472afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import List\n",
    "from datasets import load_dataset\n",
    "from torch_geometric.nn import Linear\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn.conv import HGTConv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from config import ROOT_DIR\n",
    "from src.utils import node_types, metadata\n",
    "from src.medical_hgt.dataset_builder import MedicalQADatasetBuilder\n",
    "from src.medical_hgt.ml_utils import compute_llm_confidence_diff, query_chatbot, find_subgraph_bfs, find_most_relevant_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe72ef4-6b2f-4bb3-8a49-542ef0618cfb",
   "metadata": {},
   "source": [
    "## HGT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d61f595-d030-49e4-8b25-b2ae4485ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "\n",
    "        for node_type in node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "\n",
    "        for _ in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels, hidden_channels, metadata, num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_dict = {node_type: self.lin_dict[node_type](x).relu_() for node_type, x in data.x_dict.items()}\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, data.edge_index_dict)\n",
    "\n",
    "        return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49ae1d0f-3658-4d3c-9fe9-0ce285626dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def forward(self, x_question: torch.Tensor, x_answer: torch.Tensor, pos_edge_label_index: torch.Tensor, neg_edge_label_index: torch.Tensor) -> (torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        Our decoder applies the dot-product between source and destination node embeddings to derive edge-level predictions:\n",
    "        \n",
    "        Args:\n",
    "        x_question (torch.Tensor): Embeddings of 'question' nodes.\n",
    "        x_answer (torch.Tensor): Embeddings of 'answer' nodes.\n",
    "        pos_edge_label_index (torch.Tensor): Indices of positive edges (edges that exist).\n",
    "        neg_edge_label_index (torch.Tensor): Indices of negative edges (edges that do not exist).\n",
    "\n",
    "        Returns:\n",
    "        tuple: A tuple containing two tensors (pos_pred, neg_pred) representing the predicted probabilities\n",
    "               for positive and negative edges, respectively.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        pos_edge_feat_question = x_question[pos_edge_label_index[0]]\n",
    "        pos_edge_feat_answer = x_answer[pos_edge_label_index[1]]\n",
    "\n",
    "        pos_pred = F.sigmoid((pos_edge_feat_question * pos_edge_feat_answer).sum(dim=-1))\n",
    "\n",
    "        if pos_pred.dim() == 0:\n",
    "            pos_pred = pos_pred.view(1)\n",
    "\n",
    "        neg_edge_feat_question = x_question[neg_edge_label_index[0]]\n",
    "        neg_edge_feat_answer = x_answer[neg_edge_label_index[1]]\n",
    "\n",
    "        neg_pred = F.sigmoid((neg_edge_feat_question * neg_edge_feat_answer).sum(dim=-1))\n",
    "\n",
    "        if neg_pred.dim() == 0:\n",
    "            neg_pred = neg_pred.view(1)\n",
    "\n",
    "        return pos_pred, neg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bcb28cfb-9f93-45c1-8fed-6d966a3c45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalHGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels=64):\n",
    "        super().__init__()\n",
    "        self.hgt = HGT(hidden_channels=hidden_channels, out_channels=64, num_heads=2, num_layers=1)\n",
    "        self.decoder = Decoder()\n",
    "        self.grads = {}  # for debugging purposes\n",
    "\n",
    "    def forward(self, batch_data: HeteroData) -> (torch.Tensor, torch.Tensor, dict):\n",
    "\n",
    "        self.grads = {}  # for debugging purposes\n",
    "        z_dict = self.hgt(batch_data)\n",
    "        for node_type in z_dict.keys():\n",
    "            if z_dict[node_type].requires_grad:\n",
    "                z_dict[node_type].register_hook(self.save_grad(node_type))  # for debugging purposes\n",
    "\n",
    "        pos_pred, neg_pred = self.decoder(\n",
    "            z_dict[\"question\"],\n",
    "            z_dict[\"answer\"],\n",
    "            batch_data[\"question\", \"question_correct_answer\", \"answer\"].edge_label_index,\n",
    "            batch_data[\"question\", \"question_wrong_answer\", \"answer\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pos_pred, neg_pred, z_dict\n",
    "\n",
    "    def save_grad(self, name):\n",
    "        def hook(grad):\n",
    "            self.grads[name] = grad\n",
    "\n",
    "        return hook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac1833-6a7f-4873-ae7b-bf533e3f980d",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "114041f2-682d-49d3-86f0-0ca1620ceff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM(torch.nn.Module):\n",
    "    # def __init__(self, model_name=\"meta-llama/Llama-2-7b-chat-hf\"):\n",
    "    #     super().__init__()\n",
    "    #     self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    #     self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, knowledge_nodes_dict, nx_graph_data, dataset_question_dict, correct_answer):\n",
    "\n",
    "        correct_answer_dict = {0: 'opa', 1: 'opb', 2: 'opc', 3: 'opd'}\n",
    "        output_instructions = f'how confident are you that the correct answer is {correct_answer_dict[correct_answer]}? Return a float between 0 and 1.'\n",
    "        confidence_without_context = query_chatbot(str(dataset_question_dict), output_instructions)\n",
    "\n",
    "        confidence_diffs_dict = {}  # a dict of dicts in the form {node_type_0: {node_index_0: conf_diff_0, node_index_1: conf_diff_1...}, ...}\n",
    "        for node_type, nodes_uids in knowledge_nodes_dict.items():\n",
    "            if node_type not in confidence_diffs_dict:\n",
    "                confidence_diffs_dict[node_type] = {}\n",
    "                for node_uid in nodes_uids:\n",
    "                    node_name = nx_graph_data.nodes[node_uid.item()]['name']\n",
    "                    dataset_question_dict['context'] = f'The {node_type} {node_name}.'\n",
    "                    confidence_with_context = query_chatbot(str(dataset_question_dict), output_instructions)\n",
    "                    llm_confidence_diff = compute_llm_confidence_diff(float(confidence_without_context), float(confidence_with_context))\n",
    "                    confidence_diffs_dict[node_type][node_uid] = llm_confidence_diff\n",
    "\n",
    "        return confidence_diffs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0f111-5895-4417-8542-f321db9be1ff",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a09922-3c9a-44b2-8a28-9d4c3bbbc080",
   "metadata": {},
   "source": [
    "### Define helper classes and methods for logging and tracking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f47d8eb4-520d-491b-965a-c028d6138f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class EpochResult:\n",
    "    # \"index\" of the epoch\n",
    "    # (this is also discernable from the position in ModelResult.epoch_results)\n",
    "    epoch_num: int\n",
    "\n",
    "    # Unix timestamps (seconds) when the epoch started/finished training, but not\n",
    "    # counting evaluation\n",
    "    train_start_time: int\n",
    "    train_end_time: int\n",
    "\n",
    "    # mean train loss taken across all batches\n",
    "    mean_train_loss: float\n",
    "\n",
    "    # accuracy on the training/validation set at the end of this epoch\n",
    "    train_acc: float\n",
    "    val_acc: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7261ca1-a193-4646-a0b9-05b9a84b85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelResult:\n",
    "    # Unix timestamp for when the model started training\n",
    "    start_time: int\n",
    "    # Unix timestamp for when the model completely finished (including evaluation\n",
    "    # on the test set)\n",
    "    end_time: int\n",
    "\n",
    "    # list of EpochResults -- see above\n",
    "    epoch_results: list\n",
    "\n",
    "    # model state for reloading\n",
    "    state_dict: dict\n",
    "\n",
    "    # final accuracy on the full test set (after all epochs)\n",
    "    test_acc: float\n",
    "\n",
    "    def get_total_train_time_sec(self):\n",
    "        \"\"\"\n",
    "        Helper function for calculating the total amount of time spent training, not\n",
    "        counting evaluation. In other words, this only counts the forward pass, the\n",
    "        loss calculation, and backprop for each batch.\n",
    "        \"\"\"\n",
    "        return sum([\n",
    "            er.train_end_time - er.train_start_time\n",
    "            for er in self.epoch_results])\n",
    "\n",
    "    def get_total_train_time_min(self):\n",
    "        \"\"\"get_total_train_time_sec, converted to minutes. See above.\"\"\"\n",
    "        return self.get_total_train_time_sec() // 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90348a97-043a-4ae3-aebf-2bb83449bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    \"\"\"Returns the current Unix (epoch) timestamp, in seconds.\"\"\"\n",
    "    return round(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc21a3-667d-494d-b784-d4710f9e29a8",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "282940b3-173a-4778-8c70-66da1488f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_link_prediction_loss(pos_preds: torch.Tensor, neg_preds: torch.Tensor, pos_labels: torch.Tensor, neg_labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    pos_preds (torch.Tensor): Predictions for positive links, expected to be logits.\n",
    "    neg_preds (torch.Tensor): Predictions for negative links, expected to be logits.\n",
    "    pos_labels (torch.Tensor): Ground truth labels for positive links.\n",
    "    neg_labels (torch.Tensor): Ground truth labels for negative links.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The combined binary cross-entropy loss for positive and negative predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate loss for positive predictions\n",
    "    pos_loss = F.binary_cross_entropy_with_logits(pos_preds, pos_labels.view(-1).float())\n",
    "\n",
    "    # Calculate loss for negative predictions\n",
    "    neg_loss = F.binary_cross_entropy_with_logits(neg_preds, neg_labels.view(-1).float())\n",
    "\n",
    "    # Combine the losses\n",
    "    total_loss = pos_loss + (neg_loss / 3)\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cffdeac5-06f1-4d10-8ae8-9ed11fbb45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_llm_relevancy_loss(batch, z_dict, gradients_per_questions_list):\n",
    "    # Initialize loss\n",
    "    loss = 0.0\n",
    "    num_nodes = 0\n",
    "\n",
    "    # Iterate over all nodes to form triplets and compute loss\n",
    "    for question_embedding, grads_dict in gradients_per_questions_list:\n",
    "        for node_type, grad_info_dict in grads_dict.items():\n",
    "            batch_node_indices = [torch.where(batch[node_type].node_uid == x)[0][0] for x in list(grad_info_dict.keys())]\n",
    "            gradients_list = list(grad_info_dict.values())\n",
    "            for i, node_index in enumerate(batch_node_indices):\n",
    "                current_node_embedding = torch.index_select(z_dict[node_type], 0, node_index)\n",
    "\n",
    "                # Calculate the distance between the node embedding and the central node embedding\n",
    "                distance = torch.norm(current_node_embedding - question_embedding, p=2)\n",
    "\n",
    "                # Determine the weight based on relevance\n",
    "                relevance = gradients_list[i]\n",
    "\n",
    "                # For positive relevance, penalize being far from the central node\n",
    "                # For negative relevance, penalize being close to the central node\n",
    "                if relevance > 0:\n",
    "                    weighted_loss = relevance * distance\n",
    "                elif relevance < 0:\n",
    "                    # Invert the distance measure for negative relevance\n",
    "                    weighted_loss = -relevance * (1 / (distance + 1e-6))  # adding a small constant to avoid division by zero\n",
    "                else:  # relevance is around 0, neutral\n",
    "                    weighted_loss = 0\n",
    "\n",
    "                # Accumulate the loss\n",
    "                loss += weighted_loss\n",
    "\n",
    "            num_nodes += len(gradients_list)\n",
    "\n",
    "    return loss / num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebdac81-81f1-4da9-addc-35e8149df35f",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "59bb5306-9cea-4be3-94a3-655ff2582e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(medical_hgt, split_loaders, split_name, device, prime_kg, frac=1.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    model (torch.nn.Module): The model to evaluate.\n",
    "    split_loaders (dict): A dictionary containing the data loaders for different splits.\n",
    "    split_name (str): The name of the split to evaluate (e.g., 'val', 'test').\n",
    "    device (torch.device): The device to run the model on.\n",
    "    frac (float): Fraction of the dataset to use for evaluation.\n",
    "\n",
    "    Returns:\n",
    "    float: The ROC AUC score for the evaluated split.\n",
    "    \"\"\"\n",
    "    medical_hgt.eval()\n",
    "\n",
    "    pos_y_true_tensors = []\n",
    "    neg_y_true_tensors = []\n",
    "    pos_y_pred_tensors = []\n",
    "    neg_y_pred_tensors = []\n",
    "\n",
    "    loader = split_loaders[split_name]\n",
    "    num_batches = round(frac * len(loader))\n",
    "\n",
    "    for i, batch in enumerate(loader):\n",
    "        batch_num = i + 1\n",
    "        print(f'\\r{split_name} batch {batch_num} / {num_batches}', end='')\n",
    "\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pos_pred, neg_pred, z_dict = medical_hgt(batch)\n",
    "\n",
    "            pos_eval_y = batch[\"question\", \"question_correct_answer\", \"answer\"].edge_label.squeeze()\n",
    "            neg_eval_y = batch[\"question\", \"question_wrong_answer\", \"answer\"].edge_label.squeeze()\n",
    "\n",
    "            if pos_eval_y.dim() == 0:\n",
    "                pos_eval_y = pos_eval_y.view(1)\n",
    "\n",
    "            if neg_eval_y.dim() == 0:\n",
    "                neg_eval_y = neg_eval_y.view(1)\n",
    "\n",
    "            pos_y_pred_tensors.append(pos_pred.detach())\n",
    "            neg_y_pred_tensors.append(neg_pred.detach())\n",
    "            pos_y_true_tensors.append(pos_eval_y.detach())\n",
    "            neg_y_true_tensors.append(neg_eval_y.detach())\n",
    "\n",
    "            knowledge_nodes_per_question_dict = {}\n",
    "            for node_index, question_node_representation in enumerate(z_dict['question']):\n",
    "                subgraph_nodes_uid_dict = find_subgraph_bfs(batch, node_index, 'question')\n",
    "                question_node_uid = batch['question'].node_uid[node_index]\n",
    "                most_relevant_nodes = find_most_relevant_nodes(batch, z_dict, question_node_representation, subgraph_nodes_uid_dict, prime_kg)\n",
    "                knowledge_nodes_per_question_dict[question_node_uid] = most_relevant_nodes\n",
    "\n",
    "        if batch_num >= num_batches:\n",
    "            break\n",
    "\n",
    "    medical_hgt.train()\n",
    "\n",
    "    pos_pred = torch.cat(pos_y_pred_tensors, dim=0).numpy()\n",
    "    neg_pred = torch.cat(neg_y_pred_tensors, dim=0).numpy()\n",
    "    pos_true = torch.cat(pos_y_true_tensors, dim=0).numpy()\n",
    "    neg_true = torch.cat(neg_y_true_tensors, dim=0).numpy()\n",
    "\n",
    "    pred = np.concatenate([pos_pred, neg_pred])\n",
    "    true = np.concatenate([pos_true, neg_true])\n",
    "\n",
    "    return roc_auc_score(true, pred), knowledge_nodes_per_question_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "866a5d3e-b07b-4a9e-9212-6f80ce17df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(medical_hgt, llm, split_loaders, device, file_name, qa_dataset, prime_kg, num_epochs=30, lr=0.001):\n",
    "    medical_hgt = medical_hgt.to(device)\n",
    "    llm = llm.to(device)\n",
    "\n",
    "    medical_hgt.train()\n",
    "    llm.train()\n",
    "\n",
    "    opt = torch.optim.Adam(medical_hgt.parameters(), lr=lr)\n",
    "\n",
    "    start_time = get_time()\n",
    "    print(f'start time: {start_time}; will save results to {file_name}')\n",
    "\n",
    "    train_loader = split_loaders['train']\n",
    "\n",
    "    epoch_results = []\n",
    "\n",
    "    for epoch_num in range(1, num_epochs + 1):\n",
    "        train_start_time = get_time()\n",
    "\n",
    "        train_losses = []\n",
    "        pos_y_pred_tensors = []\n",
    "        neg_y_pred_tensors = []\n",
    "        pos_y_true_tensors = []\n",
    "        neg_y_true_tensors = []\n",
    "\n",
    "        num_batches = len(train_loader)\n",
    "\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            batch_num = i + 1\n",
    "\n",
    "            # this is a carriage return trick for overwriting past lines\n",
    "            print(f'\\rEpoch {epoch_num}: batch {batch_num} / {num_batches}', end='')\n",
    "\n",
    "            opt.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # internally, the medical_hgt is applied using all the batch's edges (i.e.,\n",
    "            # batch.edge_index) but only outputs predictions on edges to be labeled\n",
    "            # (i.e., batch.edge_label_index).\n",
    "            pos_train_pred, neg_train_pred, z_dict = medical_hgt(batch)\n",
    "\n",
    "            pos_train_y = batch[\"question\", \"question_correct_answer\", \"answer\"].edge_label.squeeze()\n",
    "            neg_train_y = batch[\"question\", \"question_wrong_answer\", \"answer\"].edge_label.squeeze()\n",
    "\n",
    "            if pos_train_y.dim() == 0:\n",
    "                pos_train_y = pos_train_y.view(1)\n",
    "\n",
    "            if neg_train_y.dim() == 0:\n",
    "                neg_train_y = neg_train_y.view(1)\n",
    "\n",
    "            confidence_diffs_per_question = []  # a list of tuples (question_embeddings, conf_diffs_dict_per_question)\n",
    "            # compute the llm's feedback per question in the batch\n",
    "            for node_index, question_node_representation in enumerate(z_dict['question']):\n",
    "                qa_index = batch['question'].node_uid[node_index].item()\n",
    "                subgraph_nodes_uid_dict = find_subgraph_bfs(batch, node_index, 'question')\n",
    "                prompt_dict = dict(qa_dataset.iloc[qa_index].drop(['id', 'cop', 'exp']))\n",
    "                correct_answer = qa_dataset.iloc[qa_index]['cop']\n",
    "                current_confidence_diffs_dict = llm(subgraph_nodes_uid_dict, prime_kg, prompt_dict, correct_answer)\n",
    "                confidence_diffs_per_question.append((question_node_representation, current_confidence_diffs_dict))\n",
    "                break\n",
    "\n",
    "            link_prediction_loss = compute_link_prediction_loss(pos_train_pred, neg_train_pred, pos_train_y, neg_train_y)\n",
    "            llm_relevancy_loss = compute_llm_relevancy_loss(batch, z_dict, confidence_diffs_per_question)\n",
    "\n",
    "            total_loss = (link_prediction_loss + (llm_relevancy_loss * 0.01))\n",
    "            total_loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            pos_y_pred_tensors.append(pos_train_pred.detach())\n",
    "            neg_y_pred_tensors.append(neg_train_pred.detach())\n",
    "            pos_y_true_tensors.append(pos_train_y.detach().long())\n",
    "            neg_y_true_tensors.append(neg_train_y.detach().long())\n",
    "\n",
    "            train_losses.append(total_loss.detach().item())\n",
    "            break\n",
    "\n",
    "        train_end_time = get_time()\n",
    "\n",
    "        pos_pred = torch.cat(pos_y_pred_tensors, dim=0).numpy()\n",
    "        neg_pred = torch.cat(neg_y_pred_tensors, dim=0).numpy()\n",
    "        pos_true = torch.cat(pos_y_true_tensors, dim=0).numpy()\n",
    "        neg_true = torch.cat(neg_y_true_tensors, dim=0).numpy()\n",
    "\n",
    "        pred = np.concatenate([pos_pred, neg_pred])\n",
    "        true = np.concatenate([pos_true, neg_true])\n",
    "\n",
    "        # the training ROC AUC is computed using all the predictions (and ground\n",
    "        # truth labels) made during the entire epoch, across all batches. Note that\n",
    "        # this is arguably a bit inconsistent with validation below since it doesn't\n",
    "        # give the medical_hgt a \"second try\" for earlier batches, for which it couldn't\n",
    "        # have yet applied anything it learned in later batches.\n",
    "        train_acc = roc_auc_score(true, pred)\n",
    "\n",
    "        # The validation ROC AUC is computed by running through the validation set\n",
    "        # at the end of every epoch.\n",
    "        val_acc, val_most_relevant_nodes = evaluate_model(medical_hgt, split_loaders, 'val', device, prime_kg=prime_kg)\n",
    "\n",
    "        epoch_result = EpochResult(\n",
    "            epoch_num=epoch_num,\n",
    "            train_start_time=train_start_time,\n",
    "            train_end_time=train_end_time,\n",
    "            mean_train_loss=round(np.mean(train_losses), 4),\n",
    "            train_acc=round(train_acc, 4),\n",
    "            val_acc=round(val_acc, 4)\n",
    "        )\n",
    "\n",
    "        epoch_results.append(epoch_result)\n",
    "        print(f'\\r{epoch_result}')\n",
    "\n",
    "    state_dict = copy.deepcopy(medical_hgt.state_dict())\n",
    "    test_acc, test_most_relevant_nodes = evaluate_model(medical_hgt, split_loaders, 'test', device, prime_kg=prime_kg)\n",
    "\n",
    "    medical_hgt.eval()\n",
    "\n",
    "    end_time = get_time()\n",
    "    medical_hgt_result = ModelResult(start_time, end_time, epoch_results, state_dict, round(test_acc, 4))\n",
    "    torch.save(medical_hgt_result, file_name)\n",
    "\n",
    "    train_time_min = medical_hgt_result.get_total_train_time_min()\n",
    "    print(f'\\rTest Accuracy: {test_acc:.3f}; Total Train Time: {train_time_min} min')\n",
    "\n",
    "    return medical_hgt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba6b9a0-001c-47e8-9381-fb3a0242d1a7",
   "metadata": {},
   "source": [
    "### Set up training experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f2706a6-5027-4714-8c97-44374f998af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_loader_params, device, runs=2, train_data_path=None, val_data_path=None, test_data_path=None):\n",
    "    \"\"\"Runs a multi-trial experiment using the given DataLoaderParams.\"\"\"\n",
    "    # todo: instead of calling build_link_neighbor_loaders call MedicalQADatasetBuilder (make necessary adjustments) - loaders = dataset_builder.train_mini_batches, dataset_builder.val_mini_batches, dataset_builder.test_mini_batched\n",
    "    if train_data_path is None:\n",
    "        dataset_builder = MedicalQADatasetBuilder(\n",
    "            ['datasets/graph_dataset_30_11_23/train'],\n",
    "            val_ratio=data_loader_params.val_ratio,\n",
    "            test_ratio=data_loader_params.test_ratio,\n",
    "            disjoint_train_edges_ratio=data_loader_params.disjoint_train_edges_ratio,\n",
    "            negative_sampling_ratio=data_loader_params.negative_sampling_ratio,\n",
    "            batch_size=64)\n",
    "\n",
    "        loaders = {'train': dataset_builder.train_mini_batches, 'val': dataset_builder.val_mini_batches, 'test': dataset_builder.test_mini_batches}\n",
    "        qa_dataset = dataset_builder.qa_dataset\n",
    "    else:\n",
    "        train_data = pickle.load(open(train_data_path, 'rb'))\n",
    "        val_data = pickle.load(open(val_data_path, 'rb'))\n",
    "        test_data = pickle.load(open(test_data_path, 'rb'))\n",
    "\n",
    "        loaders = {'train': train_data, 'val': val_data, 'test': test_data}\n",
    "        qa_dataset = load_dataset(\"medmcqa\")\n",
    "        qa_dataset = pd.DataFrame(qa_dataset['train'])\n",
    "\n",
    "    prime_kg = pickle.load(open(os.path.join(ROOT_DIR, 'datasets/primeKG_nx_medium.pickle'), 'rb'))\n",
    "\n",
    "    for i in range(runs):\n",
    "        file_name = data_loader_params.get_file_name() + f'_run{i + 1}.pth'\n",
    "        # model = Model(all_edges_dict, hidden_channels=64)\n",
    "        medical_hgt = MedicalHGT(hidden_channels=64)\n",
    "        llm = LLM()\n",
    "        train_model(medical_hgt, llm, loaders, device, file_name, num_epochs=data_loader_params.num_epochs, qa_dataset=qa_dataset, prime_kg=prime_kg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d06dae30-447b-45fd-b700-bbeadf2ee622",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DataLoaderParams:\n",
    "    \"\"\"Helper class for holding the parameters of LinkNeighborLoader.\"\"\"\n",
    "    val_ratio: float\n",
    "    test_ratio: float\n",
    "    disjoint_train_edges_ratio: float\n",
    "    negative_sampling_ratio: int\n",
    "    batch_size: int\n",
    "    num_epochs: int\n",
    "\n",
    "    def get_file_name(self):\n",
    "        \"\"\"Generates the file name for storing the results, based on the params.\"\"\"\n",
    "        folder_path = os.path.join(ROOT_DIR, 'experiments')\n",
    "        return f'{folder_path}/dataloader-{self.negative_sampling_ratio}-{self.val_ratio}-{self.test_ratio}-{self.negative_sampling_ratio}-{self.batch_size}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf3678f-dc7b-498b-b92b-9b07815a5c38",
   "metadata": {},
   "source": [
    "### Prepare preprocessed dataloaders, QA Dataset (MedMCQA) and the Knowledge Grapg (PrimeKG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "680ac6bf-a32d-44ad-bf26-434fb4ae951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(ROOT_DIR, 'datasets/train_data_01_12_23.pickle')\n",
    "val_data_path = os.path.join(ROOT_DIR, 'datasets/val_data_01_12_23.pickle')\n",
    "test_data_path = os.path.join(ROOT_DIR, 'datasets/test_data_01_12_23.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdf023-41bd-48b0-968d-08bfeef951bf",
   "metadata": {},
   "source": [
    "### Run training experiment model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "594311b4-0586-4161-8c18-da4d2fcac406",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5059276-1bb4-4c9f-a65c-32bab34140b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_params_list = [\n",
    "    # baseline\n",
    "    DataLoaderParams(val_ratio=0.1, test_ratio=0.1, disjoint_train_edges_ratio=0.9, negative_sampling_ratio=3, batch_size=64, num_epochs=100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5db3f971-4a18-4de1-8105-53ee41254352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset medmcqa (/Users/shiraben-david/.cache/huggingface/datasets/medmcqa/default/1.1.0/f2fdfa9ccfbf9d148c0639e6afe3379f3c7e95c4d52d5e68ec1156e5004bd880)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32cfc08e98b742cab21523e35e6bea66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 1701616074; will save results to /Users/shiraben-david/Documents/TUB/Thesis/MedTransNet/experiments/dataloader-3-0.1-0.1-3-64_run1.pth\n",
      "val batch 32 / 86/ 77"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m datat_loader_params_params \u001b[38;5;129;01min\u001b[39;00m data_loader_params_list:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatat_loader_params_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 31\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(data_loader_params, device, runs, train_data_path, val_data_path, test_data_path)\u001b[0m\n\u001b[1;32m     29\u001b[0m medical_hgt \u001b[38;5;241m=\u001b[39m MedicalHGT(hidden_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m     30\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLM()\n\u001b[0;32m---> 31\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedical_hgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqa_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqa_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprime_kg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprime_kg\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 97\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(medical_hgt, llm, split_loaders, device, file_name, qa_dataset, prime_kg, num_epochs, lr)\u001b[0m\n\u001b[1;32m     93\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m roc_auc_score(true, pred)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# The validation ROC AUC is computed by running through the validation set\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# at the end of every epoch.\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m val_acc, val_most_relevant_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmedical_hgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprime_kg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprime_kg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m epoch_result \u001b[38;5;241m=\u001b[39m EpochResult(\n\u001b[1;32m    100\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch_num,\n\u001b[1;32m    101\u001b[0m     train_start_time\u001b[38;5;241m=\u001b[39mtrain_start_time,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     val_acc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m(val_acc, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    106\u001b[0m )\n\u001b[1;32m    108\u001b[0m epoch_results\u001b[38;5;241m.\u001b[39mappend(epoch_result)\n",
      "Cell \u001b[0;32mIn[66], line 48\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(medical_hgt, split_loaders, split_name, device, prime_kg, frac)\u001b[0m\n\u001b[1;32m     46\u001b[0m knowledge_nodes_per_question_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node_index, question_node_representation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(z_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 48\u001b[0m     subgraph_nodes_uid_dict \u001b[38;5;241m=\u001b[39m \u001b[43mfind_subgraph_bfs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     question_node_uid \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnode_uid[node_index]\n\u001b[1;32m     50\u001b[0m     most_relevant_nodes \u001b[38;5;241m=\u001b[39m find_most_relevant_nodes(batch, z_dict, question_node_representation, subgraph_nodes_uid_dict, prime_kg)\n",
      "File \u001b[0;32m~/Documents/TUB/Thesis/MedTransNet/src/medical_hgt/ml_utils.py:306\u001b[0m, in \u001b[0;36mfind_subgraph_bfs\u001b[0;34m(graph, start_node_index, start_node_type)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Find the neighbors\u001b[39;00m\n\u001b[1;32m    305\u001b[0m neighbors \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m1\u001b[39m][edge_index[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m current_node] \u001b[38;5;28;01mif\u001b[39;00m node_type \u001b[38;5;241m==\u001b[39m edge_type[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m edge_index[\u001b[38;5;241m0\u001b[39m][edge_index[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m current_node]\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m neighbor \u001b[38;5;129;01min\u001b[39;00m neighbors:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (neighbor\u001b[38;5;241m.\u001b[39mitem(), other_node_type) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m visited_nodes:\n\u001b[1;32m    308\u001b[0m         visited_nodes\u001b[38;5;241m.\u001b[39madd((neighbor\u001b[38;5;241m.\u001b[39mitem(), other_node_type))\n",
      "File \u001b[0;32m~/Documents/TUB/Thesis/MedTransNet/venv/lib/python3.10/site-packages/torch/_tensor.py:920\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    910\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing len to get tensor shape might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommended usage would be tensor.shape[0]. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    916\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    917\u001b[0m         )\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[1;32m    922\u001b[0m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;66;03m# save us work, and also helps keep trace ordering deterministic\u001b[39;00m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;66;03m# (e.g., if you zip(*hiddens), the eager map will force all the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;66;03m# indexes of hiddens[0] before hiddens[1], while the generator\u001b[39;00m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;66;03m# map will interleave them.)\u001b[39;00m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration over a 0-d tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1758\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/TUB/Thesis/MedTransNet/venv/lib/python3.10/site-packages/debugpy/_vendored/pydevd/_pydev_bundle/pydev_is_thread_alive.py:9\u001b[0m, in \u001b[0;36mis_thread_alive\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      6\u001b[0m _temp \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mThread()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_temp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_stopped\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Python 3.x has this\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_thread_alive\u001b[39m(t):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(_temp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Thread__stopped\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Python 2.x has this\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for datat_loader_params_params in data_loader_params_list:\n",
    "    run_experiment(datat_loader_params_params, device, train_data_path=train_data_path, val_data_path=val_data_path, test_data_path=test_data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9a2aa-4715-4e95-bbc8-81769f7cd3d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
